{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# =========================\n",
    "# 1. 数据加载\n",
    "# =========================\n",
    "\n",
    "train_path = \"../liar_dataset/processed_dataset/processed_train.csv\"\n",
    "valid_path = \"../liar_dataset/processed_dataset/processed_valid.csv\"\n",
    "test_path  = \"../liar_dataset/processed_dataset/processed_test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "valid_data = pd.read_csv(valid_path)\n",
    "test_data  = pd.read_csv(test_path)\n",
    "\n",
    "# 如果你的label是文本形式，需要先映射数字；如果已经是0~5，可跳过\n",
    "label_mapping = {\n",
    "    \"pants-fire\":   0,\n",
    "    \"false\":        1,\n",
    "    \"barely-true\":  2,\n",
    "    \"half-true\":    3,\n",
    "    \"mostly-true\":  4,\n",
    "    \"true\":         5\n",
    "}\n",
    "# 应对可能是文本标签的情形\n",
    "if train_data[\"label\"].dtype == object:\n",
    "    train_data[\"label\"] = train_data[\"label\"].map(label_mapping)\n",
    "    valid_data[\"label\"] = valid_data[\"label\"].map(label_mapping)\n",
    "    test_data[\"label\"]  = test_data[\"label\"].map(label_mapping)\n",
    "\n",
    "# =========================\n",
    "# 2. Tokenizer & Padding\n",
    "# =========================\n",
    "\n",
    "max_words = 5000    # 只考虑常见词\n",
    "max_len   = 100     # 每条新闻句子长度上限\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_data[\"clean_statement\"])\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train_data[\"clean_statement\"])\n",
    "valid_seq = tokenizer.texts_to_sequences(valid_data[\"clean_statement\"])\n",
    "test_seq  = tokenizer.texts_to_sequences(test_data[\"clean_statement\"])\n",
    "\n",
    "train_seq = pad_sequences(train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "valid_seq = pad_sequences(valid_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "test_seq  = pad_sequences(test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "train_labels = train_data[\"label\"].values\n",
    "valid_labels = valid_data[\"label\"].values\n",
    "test_labels  = test_data[\"label\"].values\n",
    "\n",
    "# =========================\n",
    "# 3. 构建 LSTM 模型（6分类）\n",
    "# =========================\n",
    "model_6class = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_words, output_dim=128),\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=False)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(6, activation='softmax')  # 对应6分类\n",
    "])\n",
    "\n",
    "model_6class.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 4. 模型训练\n",
    "# =========================\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "history_6class = model_6class.fit(\n",
    "    train_seq, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=(valid_seq, valid_labels),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5. 可视化训练过程\n",
    "# =========================\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_6class.history['loss'], label='Train Loss')\n",
    "plt.plot(history_6class.history['val_loss'], label='Val Loss')\n",
    "plt.title('6-class LSTM - Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_6class.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_6class.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('6-class LSTM - Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# 6. 模型评估与预测\n",
    "# =========================\n",
    "y_pred_prob_6class = model_6class.predict(test_seq)\n",
    "y_pred_6class = np.argmax(y_pred_prob_6class, axis=1)\n",
    "\n",
    "print(\"=== 6-Class Classification Report ===\\n\")\n",
    "print(classification_report(test_labels, y_pred_6class))\n",
    "\n",
    "cm_6class = confusion_matrix(test_labels, y_pred_6class)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_6class, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=list(label_mapping.keys()),\n",
    "            yticklabels=list(label_mapping.keys()))\n",
    "plt.title(\"Confusion Matrix - 6 Class\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# 7. 导出预测结果\n",
    "# =========================\n",
    "result_df_6class = pd.DataFrame({\n",
    "    \"id\": test_data[\"id\"],\n",
    "    \"true_label\": test_labels,\n",
    "    \"predicted_label\": y_pred_6class\n",
    "})\n",
    "result_df_6class.to_csv(\"./predict_result_lstm_6class.csv\", index=False)\n",
    "print(\"✅ [6分类] 预测结果已保存至: ./predict_result_lstm_6class.csv\")\n"
   ],
   "id": "7a6a1e771f5fe9bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a5de297f802da29"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
